spark {
  # You can set spark configuration here
  # Waterdrop defined streaming batch duration in seconds
  spark.streaming.batchDuration = 5

  # see available properties defined by spark: https://spark.apache.org/docs/latest/configuration.html#available-properties
  spark.app.name = "Waterdrop"
  spark.executor.instances = 2
  spark.executor.cores = 1
  spark.executor.memory = "1g"
}

input {
  # This is a example input plugin **only for test and demonstrate the feature input plugin**
  kafkaStream {
    topics = "pub_perf_mon"
    consumer.bootstrap.servers = "10.0.4.185:9092"
    consumer.group.id = "waterdrop_group"
    consumer.rebalance.max.retries = 100
  }


  # If you would like to get more information about how to configure waterdrop and see full list of input plugins,
  # please go to https://interestinglab.github.io/waterdrop/#/zh-cn/configuration/base
}

filter {
 remove{
   source_field = ["offset", "topic", "timestamp", "timestampType", "partition", "key"]
 }

  split {
    source_field = "value"
    fields = ["mq_name","metric_name", "module","classify", "timestamps","host_name","cost","source_ip","receive_time"]
    delimiter = ","
  }

  # If you would like to get more information about how to configure waterdrop and see full list of filter plugins,
  # please go to https://interestinglab.github.io/waterdrop/#/zh-cn/configuration/base
}

output {
  opentsdb{
    postUrl = "http://10.0.6.122:4222/api/put?summary"
    metric_name = "pub_perf_mon"
    dimensions = ["module","classify","host_name"]
    measures = ["cost"]
    timestamp = "timestamps"
  }


  # If you would like to get more information about how to configure waterdrop and see full list of output plugins,
  # please go to https://interestinglab.github.io/waterdrop/#/zh-cn/configuration/base
}